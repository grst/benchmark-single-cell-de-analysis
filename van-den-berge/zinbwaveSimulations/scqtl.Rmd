---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.1'
      jupytext_version: 1.2.4
  kernelspec:
    display_name: Python [conda env:.conda-zinbwavezinger]
    language: python
    name: conda-env-.conda-zinbwavezinger-py
---

```{python}
import pandas as pd
import numpy as np
import scqtl
from diffxpy.api.stats import wald_test, wald_test_chisq
import diffxpy.api as de
```

```{python}
counts = pd.read_csv("./counts.tsv", sep="\t")
group = pd.read_csv("./group.tsv", sep="\t")["group"]
```

```{python}
counts
```

```{python}
group
```

```{python}
idx = [7946, 4888, 4037, 4985, 9195, 5729, 9432, 5467, 619, 2926, 3298, 6576, 2157, 7581, 1403, 6177, 4462, 1366, 5384, 7124, 5774, 9126, 1942, 5737, 6150, 9255, 2993, 6303, 5772, 117, 9212, 9835, 4748, 3155, 5351, 7960, 2536, 3656, 5385, 6137, 9644, 6493, 7990, 6883, 6398, 2194, 6537, 6269, 4999, 5945, 4105, 8049, 3034, 8684, 9169, 5454, 574, 1005, 6456, 911, 8178, 2418, 8128, 8832, 4345, 389, 9693, 2837, 5040, 582, 2613, 6994, 3169, 9587, 3411, 7169, 8189, 8658, 4572, 2031, 9024, 9512, 9656, 5106, 2881, 8653, 8682, 8184, 2527, 2377, 4933, 2682, 5200, 2415, 1034, 8261, 9626, 3865, 5777, 3554][:50]
idx.extend(range(50))
```

```{python}
umi = counts.values[idx,:].T
```

```{python}
#size_factors = np.sum(counts, axis=0).values
size_factors = np.ones(len(group))
```

## Diffxpy wald test

```{python}
test = de.test.wald(
    data=umi.astype(np.float64),
    formula_loc="~ 1 + group",
    factor_loc_totest="group",
    sample_description=pd.DataFrame().assign(group=group),
    batch_size=100,
    training_strategy="DEFAULT",
    dtype="float64",
    size_factors=size_factors,
    gene_names=counts.index
)
```

## scqtl zinb model

```{python}
num_samples = umi.shape[0]
```

```{python}
design = test.model_estim.input_data.design_loc
```

```{python}
size_factor = size_factors.reshape(1, num_samples).T
```

```{python}
# design = np.zeros((num_samples, 1))
# design = np.vstack([group, group ^ 1]).T
```

```{python}
onehot = np.ones((num_samples, 1))
```

```{python}
print(onehot.shape)
print(size_factor.shape)
print(umi.shape)
print(design.shape)
```

```{python}
init = scqtl.tf.fit(umi=umi.astype(np.float32), 
             onehot=onehot.astype(np.float32),
             design=design.astype(np.float32),
             size_factor=size_factor.astype(np.float32),
             learning_rate=1e-3,
             max_epochs=8000,
              verbose=True
             )
```

```{python}
res = scqtl.tf.fit(umi=umi.astype(np.float32), 
             onehot=onehot.astype(np.float32),
             design=design.astype(np.float32),
             size_factor=size_factor.astype(np.float32),
             learning_rate=1e-3,
             max_epochs=8000,
            warm_start=init[:3],
              verbose=True
             )
```

```{python}
import scqtl
from diffxpy.api.stats import wald_test, wald_test_chisq
import diffxpy.api as de

def test_scqtl(counts, group):
    umi = counts.values.T
    size_factors = np.ones(len(group))
    test = de.test.wald(
        data=umi.astype(np.float64),
        formula_loc="~ 1 + group",
        factor_loc_totest="group",
        sample_description=pd.DataFrame().assign(group=group),
        batch_size=100,
        training_strategy="DEFAULT",
        dtype="float64",
        size_factors=size_factors,
        gene_names=counts.index
    )
    design = test.model_estim.input_data.design_loc
    size_factor = size_factors.reshape(1, num_samples).T
    onehot = np.ones((num_samples, 1))
    init = scqtl.tf.fit(umi=umi.astype(np.float32), 
         onehot=onehot.astype(np.float32),
         design=design.astype(np.float32),
         size_factor=size_factor.astype(np.float32),
         learning_rate=1e-3,
         max_epochs=8000,
          verbose=True
    )
    res = scqtl.tf.fit(umi=umi.astype(np.float32), 
         onehot=onehot.astype(np.float32),
         design=design.astype(np.float32),
         size_factor=size_factor.astype(np.float32),
         learning_rate=1e-3,
         max_epochs=8000,
        warm_start=init[:3],
          verbose=True
    )
    wald_zinb = wald_test(res[0][0, :], np.maximum(res[1][0, :], 1e-299))
    return wald_zinb
```

```{python}
test_scqtl(counts, group)
```

```{python}
log_mu, log_phi, logodds, nb_llik, zinb_llik = res
```

```{python}
import matplotlib.pyplot as plt
```

```{python}
plt.plot(np.log(test.mean), init[0][0, :], 'o')
# plt.xscale("log")
# plt.yscale("log")
```

```{python}
umi_means = umi.mean(axis=0)
plt.plot(np.log(test.mean), np.log(umi_means), 'o')
```

```{python}
plt.plot(test.theta_mle, log_mu[0, :], 'o')
#plt.xscale("log")
#plt.yscale("log")
```

```{python}
plt.plot(init[1][0, :], log_mu[0, :], 'o')
#plt.xscale("log")
#plt.yscale("log")
```

```{python}
tmp_mu = init[0][0, :]
tmp_phi = init[1][0, :]
sd = np.sqrt(np.maximum(tmp_mu + (tmp_mu**2)/tmp_phi, 1e-10))
```

```{python}
plt.plot(test.theta_sd, sd, 'o')
```

```{python}
plt.plot(test.theta_sd, init[1][0, :], 'o')
```

```{python}
plt.plot(test.theta_sd, log_phi[0, :], 'o')
```

```{python}
ratio_mean = test.theta_mle / tmp_mu
ratio_sd = test.theta_sd / sd
plt.plot(ratio_mean, ratio_sd, 'o')
plt.xscale("log")
plt.yscale("log")
```

```{python}
wald_scqtl = wald_test(init[0][0, :], init[1][0, :])
```

```{python}
wald_zinb = wald_test(res[0][0, :], np.maximum(res[1][0, :], 1e-299))
```

```{python}
wald_diffxpy = wald_test(test.theta_mle, test.theta_sd)
```

```{python}
plt.plot(test.pval, wald_diffxpy, 'o')
plt.xscale("log")
plt.yscale("log")
```

```{python}
plt.plot(test.pval, wald_scqtl, 'o')
plt.xscale("log")
plt.yscale("log")
```

```{python}
plt.plot(wald_scqtl, wald_zinb, 'o')
plt.xscale("log")
plt.yscale("log")
```

## Example from README

```{python}

```

```{python}
import numpy as np
import scqtl

# Generate some ZINB-distributed counts
num_samples = 1000
umi = np.concatenate([scqtl.simulation.simulate(
  num_samples=num_samples,
  size=1e5,
  seed=trial)[0][:,:1] for trial in range(10)], axis=1)
size_factor = 1e5 * np.ones((num_samples, 1))

# Generate a null design matrix
design = np.zeros((num_samples, 1))

# Map all samples to one individual/condition, i.e. one set of ZINB parameters
onehot = np.ones((num_samples, 1))

# Find the NB MLE
# Important: casting to float32 is required
init = scqtl.tf.fit(
  umi=umi.astype(np.float32),
  onehot=onehot.astype(np.float32),
  design=design.astype(np.float32),
  size_factor=size_factor.astype(np.float32),
  learning_rate=1e-3,
  max_epochs=20000,
    
  verbose=True,
)

# Find the ZINB MLE, starting from the NB MLE
log_mu, log_phi, logodds, nb_llik, zinb_llik = scqtl.tf.fit(
  umi=umi.astype(np.float32),
  onehot=onehot.astype(np.float32),
  design=design.astype(np.float32),
  size_factor=size_factor.astype(np.float32),
  learning_rate=1e-3,
  max_epochs=20000,
  warm_start=init[:3],
  verbose=True)

```

```{python}
init
```

```{python}
log_mu, log_phi, logodds, nb_llik, zinb_llik
```

## Statmodels

```{python}

```

```{python}
spector_data = sm.datasets.spector.load_pandas()
```

```{python}
logit_mod = sm.Logit(spector_data.endog, spector_data.exog)
```

```{python}
logit_res = logit_mod.fit()
```

```{python}
logit_res.summary()
```

```{python}
data = pd.DataFrame().assign(gene0=counts.values.T[:, 1]).assign(group=group)
```

```{python}
zinb = sm.NegativeBinomial.from_formula("gene0 ~ 1 + group", data)
```

```{python}
zinb_res = zinb.fit(maxiter=100)
```

```{python}
zinb_res.summary()
```

```{python}
import warnings
import statsmodels.api as sm
import sys
from multiprocessing import Pool
warnings.filterwarnings('ignore')


def _fit_model(data, model_class):
    model = model_class.from_formula(
        "gene ~ 1 + group", 
         data,
         missing='raise'
    )
    try:
        res = model.fit(
            method='nm',
            disp=False,
            maxiter=5000
        )
        test = res.wald_test("group=0")
        return test.pvalue
    except: 
        return np.nan

    
def fit_models(count_matrix, group, model_class):
    p = Pool(32)
    assert len(group) == count_matrix.shape[1]
    _pvals = []
    pvals = []
    for i in range(count_matrix.shape[0]):   
        sys.stdout.write("model {}\r".format(i))
        data = pd.DataFrame().assign(gene=count_matrix.values[i, :]).assign(group=group)
        _pvals.append(p.apply_async(_fit_model, (data, model_class)))
    for i, r in enumerate(_pvals):
        sys.stdout.write("gene: {}\r".format(i))
        pvals.append(r.get())
    p.close()
    return np.array(pvals)
```

```{python}
res = fit_models(counts.iloc[:, :], group, sm.NegativeBinomial)
```

```{python}
res
```

```{python}
_, padj, _, _ = sm.stats.multipletests(res, method='bonferroni')
```

```{python}
padj
```

```{python}
np.nanmin(padj)
```

```{python}

```
